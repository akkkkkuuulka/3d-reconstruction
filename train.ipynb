{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11769963,"sourceType":"datasetVersion","datasetId":7389281}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Установка специфичной версии open3d","metadata":{}},{"cell_type":"code","source":"!pip install -U -f https://www.open3d.org/docs/latest/getting_started.html --only-binary open3d open3d --quiet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:51:45.700595Z","iopub.execute_input":"2025-05-15T17:51:45.700861Z","iopub.status.idle":"2025-05-15T17:52:08.149926Z","shell.execute_reply.started":"2025-05-15T17:51:45.700840Z","shell.execute_reply":"2025-05-15T17:52:08.148995Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Импорты","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torchvision.models import ResNet50_Weights\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimport open3d as o3d\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport cv2\nfrom tqdm import tqdm\nimport time\nimport multiprocessing\nimport matplotlib.pyplot as plt\nimport math\nfrom pathlib import Path\nimport json\nfrom torch.optim.lr_scheduler import CosineAnnealingLR","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Класс для работы с датасетом и предобработки изображений и 3d моделей","metadata":{}},{"cell_type":"code","source":"class VoxelDataset(Dataset):\n    \"\"\"Dataset for image to voxel reconstruction\"\"\"\n    def __init__(self, root_dir, transform=None, image_size=224, voxel_size=32, voxel_threshold=0.5):\n        self.root_dir = root_dir\n        self.image_size = image_size\n        self.voxel_size = voxel_size\n        self.voxel_threshold = voxel_threshold\n        \n        self.transform = transform if transform is not None else transforms.Compose([\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.images_dir = os.path.join(root_dir, 'images')\n        self.mesh_dir = os.path.join(root_dir, 'stl')\n        self.image_files = []\n        for f in os.listdir(self.images_dir):\n            if f.endswith(('.png', '.jpg', '.jpeg')):\n                mesh_file = os.path.join(self.mesh_dir, f.rsplit('.', 1)[0] + '.stl')\n                if os.path.exists(mesh_file):\n                    self.image_files.append(f)\n        \n        if not self.image_files:\n            raise RuntimeError(f\"No valid image-mesh pairs found in {self.images_dir}\")\n        \n        print(\"Preloading voxel grids...\")\n        self.voxel_grids = {}\n        with tqdm(total=len(self.image_files), desc=\"Loading voxel grids\", \n                 bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]',\n                 ncols=100, leave=True) as pbar:\n            for f in self.image_files:\n                mesh_name = os.path.join(self.mesh_dir, f.rsplit('.', 1)[0] + '.stl')\n                voxels = self._preprocess_voxel_grid(mesh_name)\n                self.voxel_grids[f] = voxels\n                pbar.update(1)\n    \n    def __len__(self):\n        return len(self.image_files)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = os.path.join(self.images_dir, self.image_files[idx])\n        image = self._preprocess_image(img_name)\n        voxels = self.voxel_grids[self.image_files[idx]]\n        \n        return {\n            'image': image,\n            'voxels': voxels.unsqueeze(0),\n            'filename': self.image_files[idx]\n        }\n    \n    def _preprocess_voxel_grid(self, mesh_path):\n        try:\n            mesh = o3d.io.read_triangle_mesh(mesh_path)\n            if not mesh.has_vertices():\n                raise ValueError(f\"Empty mesh loaded from {mesh_path}\")\n            \n            mesh.translate(-mesh.get_center())\n            vertices = np.asarray(mesh.vertices)\n            scale = np.max(np.abs(vertices))\n            if scale > 0:\n                mesh.scale(1.0 / scale, center=mesh.get_center())\n            \n            voxel_size = 2.0 / self.voxel_size  # Scale to fit in [-1, 1]³\n            voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(\n                mesh,\n                voxel_size=voxel_size\n            )\n            \n            voxels = np.zeros((self.voxel_size, self.voxel_size, self.voxel_size), dtype=np.float32)\n            voxel_centers = np.asarray([voxel.grid_index for voxel in voxel_grid.get_voxels()])\n            \n            valid_indices = np.all((voxel_centers >= 0) & (voxel_centers < self.voxel_size), axis=1)\n            voxel_centers = voxel_centers[valid_indices]\n            \n            voxels[voxel_centers[:, 0], voxel_centers[:, 1], voxel_centers[:, 2]] = 1.0\n            return torch.FloatTensor(voxels)\n            \n        except Exception as e:\n            raise RuntimeError(f\"Error preprocessing mesh file {mesh_path}: {str(e)}\")\n    \n    def _preprocess_image(self, img_path, visualize=False):\n        try:\n            image = Image.open(img_path).convert('RGB')\n            image_np = np.array(image)\n            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n            clahe = cv2.createCLAHE(clipLimit=3.4, tileGridSize=(4,4))\n            enhanced = clahe.apply(gray)\n            gamma = 1.5\n            lookUpTable = np.empty((1,256), np.uint8)\n            for i in range(256):\n                lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n            enhanced = cv2.LUT(enhanced, lookUpTable)\n            filtered = cv2.bilateralFilter(enhanced, 3, 15, 15)\n            edges = cv2.Canny(filtered, threshold1=6, threshold2=26)\n            kernel = np.ones((3,3), np.uint8)\n            edges = cv2.dilate(edges, kernel, iterations=2)\n            edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n            edges_rgb[edges > 0] = [255, 255, 255]  # Set edges to pure white\n            combined = cv2.addWeighted(image_np, 0.5, edges_rgb, 0.5, 0)\n            if visualize:\n                cv2.imshow('Edge Detection Result', combined)\n                cv2.waitKey(0)\n                cv2.destroyAllWindows()\n            combined_image = Image.fromarray(combined)\n            image = self.transform(combined_image)\n            return image\n        except Exception as e:\n            raise RuntimeError(f\"Error preprocessing image {img_path}: {str(e)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Модель","metadata":{}},{"cell_type":"code","source":"\nclass EncoderDecoder3D(nn.Module):\n    def __init__(self, voxel_size=32):\n        super(EncoderDecoder3D, self).__init__()\n        \n        # Encoder (using ResNet50)\n        weights = ResNet50_Weights.IMAGENET1K_V1\n        resnet = models.resnet50(weights=weights)\n        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n        \n        self.encoder_output_size = 2048 * 7 * 7\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(self.encoder_output_size, 4 * 4 * 4 * 64),\n            nn.BatchNorm1d(4 * 4 * 4 * 64),\n            nn.ReLU(),\n            \n            nn.ConvTranspose3d(64, 32, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(32),\n            nn.ReLU(),\n            \n            nn.ConvTranspose3d(32, 16, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(16),\n            nn.ReLU(),\n            \n            nn.ConvTranspose3d(16, 8, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm3d(8),\n            nn.ReLU(),\n            \n            nn.Conv3d(8, 1, kernel_size=3, padding=1),\n            nn.Sigmoid()\n        )\n        self.use_checkpointing = True\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        if self.use_checkpointing and self.training:\n            features = torch.utils.checkpoint.checkpoint(self.encoder, x)\n        else:\n            features = self.encoder(x)\n        \n        features = features.view(features.size(0), -1)\n        \n        x = self.decoder[0:3](features)\n        x = x.view(-1, 64, 4, 4, 4)\n        x = self.decoder[3:](x)\n        \n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Класс для тренировки модели","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, val_loader, optimizer, scheduler, device, log_dir='runs'):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = device\n        self.max_grad_norm = 1.0\n        self.accumulation_steps = 4\n        \n        self.train_losses = []\n        self.val_losses = []\n        self.train_ious = []\n        self.val_ious = []\n        self.train_dices = []\n        self.val_dices = []\n    \n    def calculate_metrics(self, pred_voxels, target_voxels):\n        pred_probs = torch.sigmoid(pred_voxels)\n        pred_voxels = (pred_probs > 0.5).float()\n        \n        # IoU\n        intersection = (pred_voxels * target_voxels).sum()\n        union = pred_voxels.sum() + target_voxels.sum() - intersection\n        iou = (intersection + 1e-6) / (union + 1e-6)\n        \n        # Dice\n        dice = (2. * intersection + 1e-6) / (pred_voxels.sum() + target_voxels.sum() + 1e-6)\n        \n        return iou.item(), dice.item()\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0\n        total_iou = 0\n        total_dice = 0\n        self.optimizer.zero_grad()\n        \n        pbar = tqdm(total=len(self.train_loader), desc=f'Epoch {epoch}')\n        for batch_idx, batch in enumerate(self.train_loader):\n            images = batch['image'].to(self.device)\n            target_voxels = batch['voxels'].to(self.device)\n            \n            pred_voxels = self.model(images)\n            loss = F.binary_cross_entropy(pred_voxels, target_voxels)\n            loss = loss / self.accumulation_steps\n            \n            loss.backward()\n            \n            if (batch_idx + 1) % self.accumulation_steps == 0:\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n            \n            # Calculate metrics\n            iou, dice = self.calculate_metrics(pred_voxels, target_voxels)\n            \n            total_loss += loss.item() * self.accumulation_steps\n            total_iou += iou\n            total_dice += dice\n            \n            pbar.update(1)\n            pbar.set_postfix({\n                'loss': f\"{loss.item() * self.accumulation_steps:.4f}\",\n                'iou': f\"{iou:.4f}\",\n                'dice': f\"{dice:.4f}\"\n            })\n            \n            if batch_idx % 5 == 0 and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        \n        pbar.close()\n        avg_loss = total_loss / len(self.train_loader)\n        avg_iou = total_iou / len(self.train_loader)\n        avg_dice = total_dice / len(self.train_loader)\n        \n        self.train_losses.append(avg_loss)\n        self.train_ious.append(avg_iou)\n        self.train_dices.append(avg_dice)\n        \n        return avg_loss, avg_iou, avg_dice\n    \n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0\n        total_iou = 0\n        total_dice = 0\n        \n        pbar = tqdm(total=len(self.val_loader), desc=f'Validation {epoch}')\n        \n        with torch.no_grad():\n            for batch_idx, batch in enumerate(self.val_loader):\n                images = batch['image'].to(self.device)\n                target_voxels = batch['voxels'].to(self.device)\n                \n                pred_voxels = self.model(images)\n                loss = F.binary_cross_entropy(pred_voxels, target_voxels)\n                \n                # Calculate metrics\n                iou, dice = self.calculate_metrics(pred_voxels, target_voxels)\n                \n                total_loss += loss.item()\n                total_iou += iou\n                total_dice += dice\n                \n                pbar.update(1)\n                pbar.set_postfix({\n                    'val_loss': f\"{loss.item():.4f}\",\n                    'iou': f\"{iou:.4f}\",\n                    'dice': f\"{dice:.4f}\"\n                })\n        \n        pbar.close()\n        avg_loss = total_loss / len(self.val_loader)\n        avg_iou = total_iou / len(self.val_loader)\n        avg_dice = total_dice / len(self.val_loader)\n        \n        self.val_losses.append(avg_loss)\n        self.val_ious.append(avg_iou)\n        self.val_dices.append(avg_dice)\n        \n        return avg_loss, avg_iou, avg_dice\n    \n    def plot_metrics(self):\n        \"\"\"Plot training and validation metrics\"\"\"\n        epochs = range(1, len(self.train_losses) + 1)\n        \n        # Create figure with subplots\n        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15))\n        \n        # Plot losses\n        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')\n        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')\n        ax1.set_title('Training and Validation Loss')\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Loss')\n        ax1.legend()\n        ax1.grid(True)\n        \n        # Plot IoU\n        ax2.plot(epochs, self.train_ious, 'b-', label='Train IoU')\n        ax2.plot(epochs, self.val_ious, 'r-', label='Val IoU')\n        ax2.set_title('Training and Validation IoU')\n        ax2.set_xlabel('Epoch')\n        ax2.set_ylabel('IoU')\n        ax2.legend()\n        ax2.grid(True)\n        \n        # Plot Dice\n        ax3.plot(epochs, self.train_dices, 'b-', label='Train Dice')\n        ax3.plot(epochs, self.val_dices, 'r-', label='Val Dice')\n        ax3.set_title('Training and Validation Dice Coefficient')\n        ax3.set_xlabel('Epoch')\n        ax3.set_ylabel('Dice Coefficient')\n        ax3.legend()\n        ax3.grid(True)\n        \n        plt.tight_layout()\n        plt.savefig('training_metrics.png', dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def train(self, num_epochs):\n        print(f\"Starting training for {num_epochs} epochs...\")\n        print(f\"Training on device: {self.device}\")\n        print(f\"Number of training batches: {len(self.train_loader)}\")\n        print(f\"Number of validation batches: {len(self.val_loader)}\")\n        \n        for epoch in range(num_epochs):\n            train_loss, train_iou, train_dice = self.train_epoch(epoch)\n            val_loss, val_iou, val_dice = self.validate(epoch)\n            \n            self.scheduler.step()\n            \n            if (epoch + 1) % 10 == 0:\n                self.save_predictions(epoch)\n            \n            print(f'\\nEpoch {epoch}:')\n            print(f'Train Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, Dice: {train_dice:.4f}')\n            print(f'Val Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}')\n        \n        self.plot_metrics()\n        self.generate_validation_predictions()\n        \n        print(\"Training completed!\")\n\ndef evaluate_voxels(pred_voxels, target_voxels):\n    pred_probs = torch.sigmoid(pred_voxels)\n    pred_voxels = (pred_probs > 0.5).float()\n    \n    # Compute IoU\n    intersection = (pred_voxels * target_voxels).sum()\n    union = pred_voxels.sum() + target_voxels.sum() - intersection\n    iou = (intersection + 1e-6) / (union + 1e-6)\n    \n    # Compute precision and recall\n    true_positives = (pred_voxels * target_voxels).sum()\n    precision = true_positives / (pred_voxels.sum() + 1e-6)\n    recall = true_positives / (target_voxels.sum() + 1e-6)\n    \n    return {\n        'iou': iou.item(),\n        'precision': precision.item(),\n        'recall': recall.item()\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(42)\nnp.random.seed(42)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Грузим данные\nprint(\"\\nLoading dataset...\")\ndataset = VoxelDataset(\n    root_dir='/kaggle/input/reconstruction',\n    voxel_size=32\n)\nprint(f\"Total dataset size: {len(dataset)} samples\")\n\n# Делим на обучающую и валидационные выборки\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=1,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=1,\n    pin_memory=True\n)\n\n# Инициализируем модель\nprint(\"\\nCreating model...\")\nmodel = EncoderDecoder3D(voxel_size=32)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=0.001,\n    weight_decay=1e-5\n)\n\nscheduler = CosineAnnealingLR(\n    optimizer,\n    T_max=100,\n    eta_min=1e-6\n)\n\nprint(\"\\nInitializing trainer...\")\ntrainer = Trainer(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    device=device\n)\n\nprint(\"\\nStarting training...\")\ntrainer.train(num_epochs=35)\n\n# Проверка на валидационных данных\nprint(\"\\nPerforming final evaluation...\")\nmodel.eval()\ntotal_metrics = {\n    'iou': 0.0,\n    'precision': 0.0,\n    'recall': 0.0\n}\nnum_batches = 0\n\nwith torch.no_grad():\n    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n        images = batch['image'].to(device)\n        target_voxels = batch['voxels'].to(device)\n        \n        pred_voxels = model(images)\n        metrics = evaluate_voxels(pred_voxels, target_voxels)\n        for k, v in metrics.items():\n            total_metrics[k] += v\n        num_batches += 1\n\navg_metrics = {k: v / num_batches for k, v in total_metrics.items()}\n\nprint(\"\\nFinal Evaluation Results:\")\nprint(f\"IoU: {avg_metrics['iou']:.4f}\")\nprint(f\"Precision: {avg_metrics['precision']:.4f}\")\nprint(f\"Recall: {avg_metrics['recall']:.4f}\")\n\nprint(\"\\nSaving final model...\")\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'final_metrics': avg_metrics\n}, 'final_model.pth')\n\nprint(\"\\nTraining and evaluation completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:11:14.790268Z","iopub.execute_input":"2025-05-15T19:11:14.791238Z","iopub.status.idle":"2025-05-15T19:18:04.576919Z","shell.execute_reply.started":"2025-05-15T19:11:14.791205Z","shell.execute_reply":"2025-05-15T19:18:04.575907Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nLoading dataset...\nPreloading voxel grids...\n","output_type":"stream"},{"name":"stderr","text":"Loading voxel grids: 100%|████████████████████████████████████████| 196/196 [00:02<00:00, 85.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Total dataset size: 196 samples\n\nCreating model...\n\nInitializing trainer...\n\nStarting training...\nStarting training for 35 epochs...\nTraining on device: cuda\nNumber of training batches: 39\nNumber of validation batches: 10\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 39/39 [00:07<00:00,  5.31it/s, loss=0.3780, iou=0.0789, dice=0.1462]\nValidation 0: 100%|██████████| 10/10 [00:01<00:00,  5.26it/s, val_loss=0.4109, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 0:\nTrain Loss: 0.6153, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.4156, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 39/39 [00:07<00:00,  5.41it/s, loss=0.3017, iou=0.0928, dice=0.1699]\nValidation 1: 100%|██████████| 10/10 [00:01<00:00,  5.31it/s, val_loss=0.2926, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1:\nTrain Loss: 0.3281, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.3074, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 39/39 [00:07<00:00,  5.42it/s, loss=0.2971, iou=0.0978, dice=0.1782]\nValidation 2: 100%|██████████| 10/10 [00:01<00:00,  5.33it/s, val_loss=0.2682, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2:\nTrain Loss: 0.2758, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2914, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 39/39 [00:07<00:00,  5.30it/s, loss=0.2839, iou=0.0905, dice=0.1660]\nValidation 3: 100%|██████████| 10/10 [00:01<00:00,  5.32it/s, val_loss=0.2570, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3:\nTrain Loss: 0.2620, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2816, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 39/39 [00:07<00:00,  5.34it/s, loss=0.2056, iou=0.0706, dice=0.1320]\nValidation 4: 100%|██████████| 10/10 [00:01<00:00,  5.25it/s, val_loss=0.2449, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4:\nTrain Loss: 0.2503, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2686, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 39/39 [00:07<00:00,  5.37it/s, loss=0.2240, iou=0.0771, dice=0.1432]\nValidation 5: 100%|██████████| 10/10 [00:01<00:00,  5.29it/s, val_loss=0.2451, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5:\nTrain Loss: 0.2393, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2650, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 39/39 [00:07<00:00,  5.43it/s, loss=0.2893, iou=0.1070, dice=0.1933]\nValidation 6: 100%|██████████| 10/10 [00:02<00:00,  4.46it/s, val_loss=0.2428, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6:\nTrain Loss: 0.2309, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2595, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 39/39 [00:07<00:00,  5.48it/s, loss=0.2105, iou=0.0814, dice=0.1506]\nValidation 7: 100%|██████████| 10/10 [00:01<00:00,  5.22it/s, val_loss=0.2326, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7:\nTrain Loss: 0.2218, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2537, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 39/39 [00:07<00:00,  5.48it/s, loss=0.2230, iou=0.0926, dice=0.1695]\nValidation 8: 100%|██████████| 10/10 [00:01<00:00,  5.21it/s, val_loss=0.2326, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8:\nTrain Loss: 0.2142, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2516, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 39/39 [00:07<00:00,  5.47it/s, loss=0.1690, iou=0.0693, dice=0.1297]\nValidation 9: 100%|██████████| 10/10 [00:01<00:00,  5.34it/s, val_loss=0.2331, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9:\nTrain Loss: 0.2069, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2540, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 39/39 [00:07<00:00,  5.42it/s, loss=0.1949, iou=0.0774, dice=0.1437]\nValidation 10: 100%|██████████| 10/10 [00:01<00:00,  5.28it/s, val_loss=0.2343, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10:\nTrain Loss: 0.2018, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2494, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 39/39 [00:07<00:00,  5.42it/s, loss=0.2231, iou=0.0993, dice=0.1807]\nValidation 11: 100%|██████████| 10/10 [00:01<00:00,  5.34it/s, val_loss=0.2225, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11:\nTrain Loss: 0.1948, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2445, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 39/39 [00:07<00:00,  5.49it/s, loss=0.2426, iou=0.1093, dice=0.1971]\nValidation 12: 100%|██████████| 10/10 [00:01<00:00,  5.32it/s, val_loss=0.2291, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12:\nTrain Loss: 0.1889, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2469, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 39/39 [00:07<00:00,  5.28it/s, loss=0.1544, iou=0.0760, dice=0.1413]\nValidation 13: 100%|██████████| 10/10 [00:01<00:00,  5.26it/s, val_loss=0.2291, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13:\nTrain Loss: 0.1846, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2445, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 39/39 [00:07<00:00,  5.45it/s, loss=0.2143, iou=0.0963, dice=0.1757]\nValidation 14: 100%|██████████| 10/10 [00:01<00:00,  5.38it/s, val_loss=0.2178, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14:\nTrain Loss: 0.1808, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2365, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 39/39 [00:07<00:00,  5.42it/s, loss=0.1555, iou=0.0787, dice=0.1460]\nValidation 15: 100%|██████████| 10/10 [00:01<00:00,  5.40it/s, val_loss=0.2154, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15:\nTrain Loss: 0.1775, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2360, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 39/39 [00:07<00:00,  5.39it/s, loss=0.1491, iou=0.0772, dice=0.1433]\nValidation 16: 100%|██████████| 10/10 [00:02<00:00,  4.89it/s, val_loss=0.2179, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16:\nTrain Loss: 0.1745, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2421, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 39/39 [00:07<00:00,  5.46it/s, loss=0.2669, iou=0.1109, dice=0.1997]\nValidation 17: 100%|██████████| 10/10 [00:01<00:00,  5.35it/s, val_loss=0.2271, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17:\nTrain Loss: 0.1715, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2453, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 39/39 [00:07<00:00,  5.36it/s, loss=0.1797, iou=0.0885, dice=0.1627]\nValidation 18: 100%|██████████| 10/10 [00:01<00:00,  5.37it/s, val_loss=0.2226, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18:\nTrain Loss: 0.1737, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2410, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 39/39 [00:07<00:00,  5.38it/s, loss=0.1543, iou=0.0777, dice=0.1441]\nValidation 19: 100%|██████████| 10/10 [00:01<00:00,  5.37it/s, val_loss=0.2140, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19:\nTrain Loss: 0.1661, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2391, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 39/39 [00:07<00:00,  5.40it/s, loss=0.1668, iou=0.0871, dice=0.1602]\nValidation 20: 100%|██████████| 10/10 [00:01<00:00,  5.35it/s, val_loss=0.2169, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20:\nTrain Loss: 0.1655, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2394, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|██████████| 39/39 [00:07<00:00,  5.42it/s, loss=0.1411, iou=0.0673, dice=0.1262]\nValidation 21: 100%|██████████| 10/10 [00:01<00:00,  5.32it/s, val_loss=0.2169, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 21:\nTrain Loss: 0.1616, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2389, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22: 100%|██████████| 39/39 [00:07<00:00,  5.48it/s, loss=0.1416, iou=0.0793, dice=0.1469]\nValidation 22: 100%|██████████| 10/10 [00:01<00:00,  5.41it/s, val_loss=0.2332, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 22:\nTrain Loss: 0.1610, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2400, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23: 100%|██████████| 39/39 [00:07<00:00,  5.24it/s, loss=0.1292, iou=0.0669, dice=0.1254]\nValidation 23: 100%|██████████| 10/10 [00:01<00:00,  5.42it/s, val_loss=0.2243, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23:\nTrain Loss: 0.1596, IoU: 0.0826, Dice: 0.1520\nVal Loss: 0.2431, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, loss=0.1860, iou=0.0962, dice=0.1755]\nValidation 24: 100%|██████████| 10/10 [00:01<00:00,  5.42it/s, val_loss=0.2204, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 24:\nTrain Loss: 0.1611, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2419, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, loss=0.1413, iou=0.0682, dice=0.1277]\nValidation 25: 100%|██████████| 10/10 [00:01<00:00,  5.41it/s, val_loss=0.2185, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25:\nTrain Loss: 0.1566, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2417, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|██████████| 39/39 [00:07<00:00,  5.36it/s, loss=0.0995, iou=0.0649, dice=0.1219]\nValidation 26: 100%|██████████| 10/10 [00:01<00:00,  5.04it/s, val_loss=0.2072, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26:\nTrain Loss: 0.1535, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2394, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27: 100%|██████████| 39/39 [00:07<00:00,  5.45it/s, loss=0.2087, iou=0.0991, dice=0.1803]\nValidation 27: 100%|██████████| 10/10 [00:01<00:00,  5.40it/s, val_loss=0.2105, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 27:\nTrain Loss: 0.1492, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2401, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28: 100%|██████████| 39/39 [00:07<00:00,  5.34it/s, loss=0.1627, iou=0.0952, dice=0.1738]\nValidation 28: 100%|██████████| 10/10 [00:01<00:00,  5.49it/s, val_loss=0.2275, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28:\nTrain Loss: 0.1477, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2483, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, loss=0.1550, iou=0.0946, dice=0.1729]\nValidation 29: 100%|██████████| 10/10 [00:01<00:00,  5.34it/s, val_loss=0.2121, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29:\nTrain Loss: 0.1471, IoU: 0.0826, Dice: 0.1521\nVal Loss: 0.2428, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, loss=0.1462, iou=0.0878, dice=0.1614]\nValidation 30: 100%|██████████| 10/10 [00:01<00:00,  5.43it/s, val_loss=0.2144, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30:\nTrain Loss: 0.1437, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2437, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|██████████| 39/39 [00:07<00:00,  5.38it/s, loss=0.1276, iou=0.0632, dice=0.1188]\nValidation 31: 100%|██████████| 10/10 [00:01<00:00,  5.44it/s, val_loss=0.2264, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31:\nTrain Loss: 0.1402, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2431, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32: 100%|██████████| 39/39 [00:07<00:00,  5.44it/s, loss=0.1398, iou=0.0975, dice=0.1776]\nValidation 32: 100%|██████████| 10/10 [00:01<00:00,  5.39it/s, val_loss=0.2217, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 32:\nTrain Loss: 0.1378, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2435, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33: 100%|██████████| 39/39 [00:07<00:00,  5.20it/s, loss=0.1390, iou=0.0633, dice=0.1191]\nValidation 33: 100%|██████████| 10/10 [00:01<00:00,  5.42it/s, val_loss=0.2281, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 33:\nTrain Loss: 0.1340, IoU: 0.0826, Dice: 0.1523\nVal Loss: 0.2474, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34: 100%|██████████| 39/39 [00:07<00:00,  5.47it/s, loss=0.1898, iou=0.0904, dice=0.1658]\nValidation 34: 100%|██████████| 10/10 [00:01<00:00,  5.22it/s, val_loss=0.2291, iou=0.0767, dice=0.1424]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34:\nTrain Loss: 0.1324, IoU: 0.0826, Dice: 0.1522\nVal Loss: 0.2468, IoU: 0.0917, Dice: 0.1674\n","output_type":"stream"},{"name":"stderr","text":"Generating validation predictions: 100%|██████████| 10/10 [00:50<00:00,  5.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Training completed!\n\nPerforming final evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 10/10 [00:01<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Evaluation Results:\nIoU: 0.0917\nPrecision: 0.0917\nRecall: 1.0000\n\nSaving final model...\n\nTraining and evaluation completed!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!zip preds /kaggle/working/validation_predictions/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:21:02.158395Z","iopub.execute_input":"2025-05-15T19:21:02.158714Z","iopub.status.idle":"2025-05-15T19:21:04.206621Z","shell.execute_reply.started":"2025-05-15T19:21:02.158685Z","shell.execute_reply":"2025-05-15T19:21:04.205846Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/validation_predictions/part_0000.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0021.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0024.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0025.png_prediction.png (deflated 7%)\n  adding: kaggle/working/validation_predictions/part_0030.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0035.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0036.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0037.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0038.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0045.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0054.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0073.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0082.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0090.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0091.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0099.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0101.png_prediction.png (deflated 10%)\n  adding: kaggle/working/validation_predictions/part_0107.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0113.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0121.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0138.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0150.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0152.png_prediction.png (deflated 8%)\n  adding: kaggle/working/validation_predictions/part_0153.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0155.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0168.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0176.png_prediction.png (deflated 10%)\n  adding: kaggle/working/validation_predictions/part_0180.png_prediction.png (deflated 8%)\n  adding: kaggle/working/validation_predictions/part_0205.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0207.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0211.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0218.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0238.png_prediction.png (deflated 4%)\n  adding: kaggle/working/validation_predictions/part_0240.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0249.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0265.png_prediction.png (deflated 7%)\n  adding: kaggle/working/validation_predictions/part_0277.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0299.png_prediction.png (deflated 5%)\n  adding: kaggle/working/validation_predictions/part_0300.png_prediction.png (deflated 6%)\n  adding: kaggle/working/validation_predictions/part_0307.png_prediction.png (deflated 4%)\n","output_type":"stream"}],"execution_count":12}]}